{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8097987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To print multiple output in a cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ece7fc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SiddharthaPaul\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd # Data manipulation and analysis library\n",
    "from sklearn.feature_selection import RFE # RFE (Recursive Feature Elimination) is for feature selection\n",
    "from sklearn.ensemble import RandomForestRegressor # Random forest modelling\n",
    "import numpy as np # For arrays and mathematical operations\n",
    "from statsmodels.tsa.stattools import adfuller # Dickey-fuller testto check stationarity of data\n",
    "from sklearn.metrics import mean_squared_error # For evaluating the model\n",
    "from sklearn.preprocessing import LabelEncoder # To encode categorical integer features\n",
    "import matplotlib.pyplot as plt # For plotting\n",
    "import seaborn as sns # Statistical data visualization\n",
    "import scipy.stats as stats # Statistical analysis\n",
    "import pylab # For plotting\n",
    "import warnings # To handle warnings\n",
    "warnings.filterwarnings(\"ignore\") # Ignore all warings\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX # To do SARIMAX\n",
    "from sklearn.model_selection import train_test_split # To split into train and test data set\n",
    "from sklearn.preprocessing import StandardScaler # For RNN: Recursive neural network\n",
    "from keras.models import Sequential # For RNN\n",
    "from keras.layers import LSTM, Dense, Dropout # For RNN\n",
    "from keras.optimizers import Adam # For RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cba96e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore all warings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58afcf9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/deepakvarier/Downloads/hackathon_data/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/deepakvarier/Downloads/hackathon_data\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m date_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, parse_dates \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweek\u001b[39m\u001b[38;5;124m'\u001b[39m], date_parser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mto_datetime(x, \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m date_format))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/deepakvarier/Downloads/hackathon_data/train.csv'"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "file_path = 'C:\\\\Users\\\\SiddharthaPaul\\\\OneDrive - Tata Business Hub Limited\\\\Desktop\\\\Hackathon'\n",
    "date_format = \"%d/%m/%y\"\n",
    "df = pd.read_csv(file_path+'\\\\train.csv', sep = ',', parse_dates = ['week'], date_parser = lambda x: pd.to_datetime(x, format = date_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601fee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characteristics of data\n",
    "df.head()\n",
    "df.shape\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aab5372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['week'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df1928",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['week'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b70cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null values in the data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd303165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since total no. of rows = 150150 and the null value is only in 1 row, therefore, we will remove the null row\n",
    "# Calculate the total number of rows\n",
    "total_rows = len(df)\n",
    "# Calculate the number of rows with missing values\n",
    "na_rows = df.isna().any(axis=1).sum()\n",
    "if na_rows < total_rows * 0.01:\n",
    "    df.dropna(inplace=True)\n",
    "else:\n",
    "    # Fill missing values with the average of store_id and sku_id combination\n",
    "    df.fillna(df.groupby(['store_id', 'sku_id']).transform('mean'), inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e191446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether there are rows where the total_price or units_sold <=0\n",
    "df.shape\n",
    "df['total_price'].loc[df['total_price']<=0].count()\n",
    "df['units_sold'].loc[df['units_sold']<=0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc4acda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows with negative rows\n",
    "con1 = df['units_sold']<=0\n",
    "con2 = df['total_price']<=0\n",
    "df = df[~(con1 & con2)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2054cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicates if any\n",
    "df.shape\n",
    "df = df.drop_duplicates(['week', 'store_id', 'sku_id'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a067c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe by date column in chronological order\n",
    "df = df.sort_values(by='week', ascending=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b75708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create data frame for the selected store_id and sku_id\n",
    "def create_dataframe(sku_id, df):\n",
    "    # Filter the data for the specified store_id and sku_id\n",
    "    filtered_data = df[(df['sku_id'] == sku_id)]\n",
    "\n",
    "    # If no data is found for the specified sku_id, return None\n",
    "    if filtered_data.empty:\n",
    "        print(\"No data found for the specified sku_id.\")\n",
    "        return None\n",
    "\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093f17cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user input for sku_id\n",
    "#sku_id = int(input(\"Enter sku_id: \"))\n",
    "sku_id=216425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61a03ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with user inputs to create dataframe of selected store_id and sku_id\n",
    "df_selected = create_dataframe(sku_id,df)\n",
    "if df_selected is not None:\n",
    "    df_selected.head()\n",
    "    df_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a9dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_selected = df_selected.drop(columns=['record_ID', 'store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f394e619",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9625818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by sku_id and week and perform aggregation\n",
    "#df_selected = df.groupby(['sku_id','week']).agg({\n",
    "#    'total_price': 'mean',\n",
    "#    'base_price': 'mean',\n",
    "#    'is_featured_sku': 'max',\n",
    "#    'is_display_sku': 'max',\n",
    "#    'units_sold': 'sum'\n",
    "#}).reset_index()\n",
    "\n",
    "# Print the aggregated DataFrame\n",
    "#print(df_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554a2094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing the data\n",
    "def preprocess_data(df):\n",
    "    # Convert 'week' column to datetime type and extract seasonality features\n",
    "    df['week'] = pd.to_datetime(df['week'])\n",
    "    df['month'] = df['week'].dt.month\n",
    "    df['year'] = df['week'].dt.year\n",
    "    df['day_of_week'] = df['week'].dt.dayofweek\n",
    "    df['day_of_month'] = df['week'].dt.day\n",
    "    df['discount'] = df['base_price'] - df['total_price']\n",
    "    # Encode categorical variables 'is_featured_sku' and 'is_display_sku'\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['is_featured_sku'] = label_encoder.fit_transform(df['is_featured_sku'])\n",
    "    df['is_display_sku'] = label_encoder.fit_transform(df['is_display_sku'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468c0d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to pre-process the data\n",
    "df_processed = preprocess_data(df_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8f1c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5eac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_processed.drop(['week'], inplace=True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125fefb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69940ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the data is stationary\n",
    "result = adfuller(df_processed['units_sold'].dropna())\n",
    "# Print the test statistic and p-value\n",
    "print('ADF Statistic:', result[0])\n",
    "print('p-value:', result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842bcd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the p-value is below 0.05,\n",
    "# the data can be assumed to be stationary hence we can proceed with the data without any transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e12d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba71f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed['units_sold'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88db18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# units sold is highly positively skewed since skewness > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b821fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.units_sold.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722c336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(df_processed.units_sold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e11038",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(df_processed['units_sold'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbfd9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Q plot\n",
    "stats.probplot(df_processed.units_sold, plot = pylab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd236f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tail of the data\n",
    "df_processed.loc[df_processed['store_id']==8091].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e824e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logarithmic transformation of data\n",
    "df_processed['units_sold'] = np.log(df_processed['units_sold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54528f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tail of the data\n",
    "df_processed.loc[df_processed['store_id']==8091].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc22b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed['units_sold'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840af018",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(df_processed['units_sold'])\n",
    "plt.subplot(1,2,2)\n",
    "stats.probplot(df_processed['units_sold'], plot = pylab)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3088f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the boundary values\n",
    "UL = df_processed['units_sold'].mean() + 3*df_processed['units_sold'].std()\n",
    "LL = df_processed['units_sold'].mean() - 3*df_processed['units_sold'].std()\n",
    "UL\n",
    "LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6aefa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0ac8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed['units_sold'].loc[df_processed['units_sold']<LL].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677cf9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed['units_sold'].loc[df_processed['units_sold']>UL].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e52893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers\n",
    "condition1 = df_processed['units_sold']>UL\n",
    "condition2 = df_processed['units_sold']<LL\n",
    "df_processed = df_processed[~(condition1 & condition2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d5e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal decompose\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f418d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of rows for testing\n",
    "test_size = int(len(df_processed)*0.2)\n",
    "end_point = len(df_processed)\n",
    "x = end_point - test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b2f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.shape\n",
    "test_size\n",
    "end_point\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d48f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "df_processed_train = df_processed.iloc[:x - 1]\n",
    "df_processed_test = df_processed.iloc[x:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ad4a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shape of test and train\n",
    "df_processed_train.shape\n",
    "df_processed_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c2b50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processed data\n",
    "df_processed_train.head()\n",
    "df_processed_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b80f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_processed_test.loc[:, df_processed_test.columns != 'units_sold']\n",
    "y_test = df_processed_test[['units_sold']]\n",
    "X_train = df_processed_train.loc[:, df_processed_train.columns != 'units_sold']\n",
    "y_train = df_processed_train[['units_sold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ecc69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()\n",
    "y_test.head()\n",
    "X_train.head()\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44762b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d100330",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sarimax = X_test\n",
    "y_test_sarimax = y_test\n",
    "X_train_sarimax = X_train\n",
    "y_train_sarimax = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b517472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()\n",
    "y_test.head()\n",
    "X_train.head()\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b5315",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b145eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.set_index('week', inplace=True)\n",
    "X_train.set_index('week', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0837aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(X_train, y_train):\n",
    "    # Creating a Random Forest regressor\n",
    "    #rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Training the model\n",
    "    #rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Making predictions on the testing set\n",
    "    rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_regressor = RFE(estimator = rf_regressor, n_features_to_select=7)\n",
    "    fit = rf_regressor.fit(X_train, y_train)\n",
    "    y_pred = fit.predict(X_test)\n",
    "    selected_features = X_train.columns[rf_regressor.support_]\n",
    "    print(\"Selected Features:\",selected_features)\n",
    "    \n",
    "    return y_pred, fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65373fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, fit = train_random_forest(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40b8f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b1e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate accuracy using MAPE\n",
    "y_true = np.array(y_test['units_sold'])\n",
    "sumvalue=np.sum(y_true)\n",
    "mape=np.sum(np.abs((y_true - y_pred)))/sumvalue*100\n",
    "accuracy=100-mape\n",
    "print('Accuracy:', round(accuracy,2),'%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ab269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find RMSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\",rmse)\n",
    "print(\"MSE:\",mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c701a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(y_test, y_pred):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred, color='blue')\n",
    "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')\n",
    "    plt.xlabel('Actual units_sold')\n",
    "    plt.ylabel('Predicted units_sold')\n",
    "    plt.title('Actual vs. Predicted units_sold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9922dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test1 = y_test.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d065b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = pd.DataFrame(data=[y_test1,y_pred]).T\n",
    "comp.columns=['y_test','y_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe856a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29089638",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cd4c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot (y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b4c6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee387ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of safety stock factor\n",
    "def calculate_safety_factor(desired_service_level, standard_deviation):\n",
    "    # Calculation Z-score corresponding to the desired service level\n",
    "    z_score = stats.norm.ppf(desired_service_level)\n",
    "    \n",
    "    #Calculate safety factor\n",
    "    safety_factor = z_score * standard_deviation\n",
    "    \n",
    "    return safety_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0d8a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user input for sku_id\n",
    "#store_id = int(input(\"Enter store_id: \"))\n",
    "store_id=8091"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a991d51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get desired service level\n",
    "#desired_service_level = float(input(\"Enter desired service level (ex: 0.95 for 95%): \"))\n",
    "desired_service_level = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68be59c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of standard_deviation\n",
    "filtered_df = df_processed[(df['store_id'] == store_id) & (df_processed['sku_id'] == sku_id)]\n",
    "standard_deviation = filtered_df['units_sold'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c80396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of re-order point\n",
    "def calculate_reorder_point (demand_forecast, lead_time, safety_factor):\n",
    "    average_demand = np.mean(demand_forecast)\n",
    "    demand_std = np.std(demand_forecast)\n",
    "    safety_stock = safety_factor * demand_std\n",
    "    safety_stock = safety_stock.round()\n",
    "    reorder_point = average_demand * lead_time + safety_stock\n",
    "    reorder_point = reorder_point.round()\n",
    "    return reorder_point, safety_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41210f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user input for sku_id\n",
    "#lead_time = int(input(\"Enter lead time in weeks: \"))\n",
    "lead_time = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8991707",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5230d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3293bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.reset_index(drop=True, inplace=True)\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a594a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df['units_sold'] = np.exp(df['units_sold'])\n",
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d652cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['units_sold'] = np.exp(test_df['units_sold'])\n",
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff61471",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_forecast = test_df[(df['store_id'] == store_id) & (df_processed['sku_id'] == sku_id)]\n",
    "demand_forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea2858",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_forecast = demand_forecast['units_sold']\n",
    "demand_forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923d6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_forecast = demand_forecast.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77361d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_factor = calculate_safety_factor(desired_service_level, standard_deviation)\n",
    "reorder_point = calculate_reorder_point (demand_forecast, lead_time, safety_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f18553",
   "metadata": {},
   "outputs": [],
   "source": [
    "reorder_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4af37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting RNN (Recurrent Neural Network)\n",
    "df_nrr = df_processed\n",
    "df_nrr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faeb680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df_nrr = df_nrr.drop(columns=['record_ID', 'week'])  # Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a9174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "df_nrr[['total_price', 'base_price']] = scaler.fit_transform(df_nrr[['total_price', 'base_price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191528b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nrr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9e8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features (X) and target (y)\n",
    "X_nrr = df_nrr.drop(columns=['units_sold'])\n",
    "y_nrr = df_nrr['units_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a616bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_nrr_train, X_nrr_test, y_nrr_train, y_nrr_test = train_test_split(X_nrr, y_nrr, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f5bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input data for LSTM\n",
    "X_nrr_train = np.array(X_nrr_train).reshape(X_nrr_train.shape[0], X_nrr_train.shape[1], 1)\n",
    "X_nrr_test = np.array(X_nrr_test).reshape(X_nrr_test.shape[0], X_nrr_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abd8902",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nrr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a2b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_nrr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc56c6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_nrr_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1158495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f371c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_nrr_train, y_nrr_train, epochs=100, batch_size=32, validation_data=(X_nrr_test, y_nrr_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab45ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_nrr_pred = model.predict(X_nrr_test).flatten()\n",
    "rmse_nrr = np.sqrt(mean_squared_error(y_nrr_test, y_nrr_pred))\n",
    "mape_nrr = np.mean(np.abs((y_nrr_test - y_nrr_pred) / y_nrr_test)) * 100\n",
    "loss_nrr = model.evaluate(X_nrr_test, y_nrr_test)\n",
    "\n",
    "print(\"Test Loss:\", loss_nrr)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse_nrr)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape_nrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d218bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(y_nrr_test, y_nrr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a73593",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse, rmse_nrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53059f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find RMSE\n",
    "mse_nrr = mean_squared_error(y_nrr_test, y_nrr_pred)\n",
    "rmse_nrr = np.sqrt(mse_nrr)\n",
    "print(\"RMSE:\",rmse_nrr)\n",
    "print(\"MSE:\",mse_nrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ec09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate accuracy using MAPE\n",
    "y_nrr_true = np.array(y_nrr_test)\n",
    "sumvalue=np.sum(y_nrr_true)\n",
    "mape_nrr=np.sum(np.abs((y_nrr_true - y_nrr_pred)))/sumvalue*100\n",
    "accuracy_nrr=100-mape_nrr\n",
    "print('Accuracy:', round(accuracy_nrr,2),'%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef4873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nrr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b82ed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nrr_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111b6ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_nrr = pd.DataFrame(data=[y_nrr_true,y_nrr_pred]).T\n",
    "comp_nrr.columns=['y_nrr_test','y_nrr_pred']\n",
    "comp_nrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4fd8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8495f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6229e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a9fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9366df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sarimax.shape\n",
    "y_train_sarimax.shape\n",
    "X_test_sarimax.shape\n",
    "y_test_sarimax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb277826",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sarimax.reset_index(drop=True, inplace=True)\n",
    "y_test_sarimax.reset_index(drop=True, inplace=True)\n",
    "X_train_sarimax.reset_index(drop=True, inplace=True)\n",
    "y_train_sarimax.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92993752",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sarimax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d52639",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sarimax = X_train_sarimax.loc[y_train_sarimax.index]  # Align indices with y_train\n",
    "y_train_sarimax = y_train_sarimax.loc[X_train_sarimax.index]  # Align indices with X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0339849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and fit the SARIMAX model\n",
    "model_sarimax = SARIMAX(endog=y_train_sarimax, exog=X_train_sarimax, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "results_sarimax = model_sarimax.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93790b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = results_sarimax.predict(start=len(y_train_sarimax), end=len(y_train_sarimax)+len(y_test_sarimax)-1, exog=X_test_sarimax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1b7ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE\n",
    "rmse_sarimax = np.sqrt(mean_squared_error(y_test_sarimax, predictions))\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse_sarimax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb920d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558f9b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate accuracy using MAPE\n",
    "y_true_sarimax = np.array(y_test_sarimax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e271e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumvalue=np.sum(y_true_sarimax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2135e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88815e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9548bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_sarimax=np.sum(np.abs((y_true_sarimax - predictions)))/sumvalue*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff174834",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_sarimax=100-mape_nrr\n",
    "print('Accuracy:', round(accuracy_sarimax,2),'%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235d9735",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse, rmse_nrr, rmse_sarimax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d038cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(rmse), np.exp(rmse_nrr), np.exp(rmse_sarimax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6faff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holt Winters\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
